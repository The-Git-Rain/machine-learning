# 线性模型
线性模型是通过一个属性的线性组合来进行预测的函数  
一般用向量形式写成  
f(x)=wt* x+b  
线性回归->试图获得一个线性模型， 使得均方误差最小 通过最小二乘法           
对数几率函数 y=1/(1+e(-z方））
z转换为wt*x+b  
y/（1-y） 为几率 上式可化为对数几率即加ln
可通过极大似然法 然后凸优化来估计w和b
线性判别分析（LDA）将投影到同一条直线上距离近的投影点分为一组，其他的分为另一组，  
即找到一条直线，使得同类样例投影点的协方差尽可能小，并且使得不同类中心之间的距离尽可能的大
LDA欲最大化的目标，即Sb与Sw的广义瑞利商  
由贝叶斯决策理论的角度来阐述，当两类数据同鲜艳，满足高斯分布且协方差相等时，LDA可达到最优分类。  
多分类：  
ovo: 一对一 变成n(n-1)/2个2分器，然后最后选出预测出最多的类别作为分类结果   
ovr：每次将一个类的样例作为正例，其他为反例 获得N个结果，选择置信度最大的类别作为分类结果，当类别很多时OVR的训练开销更大  
MvM: 即若干正例，若干反例  纠错输出码ECOC将距离最小的编码对应的类别作为预测结果  
对于类别不平衡问题： 
若y/(1-y)>m+/m-预测为正 否则为反，通过再缩放实现 
再缩放 三种方法： 欠采样， 过采样 ，阈值移动 再缩放也是代价敏感学习的基础。
