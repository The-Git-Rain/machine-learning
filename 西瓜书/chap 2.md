# 第二章模型评估与选择
训练集上的误差为训练误差或者经验误差  
新样本上的误差为泛化误差  
交叉验证法分成k个子集每次k-1个训练一个验证  
留一法 k=n;
自助法 每次随机选择样本训练然后放回样本继续训练 适合难以划分的小样本  
回归任务最常用的性能度量是均方误差  
分类结果混淆矩阵
TP(真正例） FP  
TN          FN(假反例）
查准率P= TP/(TP+FP)   
查准率R= TP/(TP+FN)   
P-R图 平衡点即R=P时时一个度量 一般来说越高越好 但过于简单  
F1 =2PR/(P+R)=2TP/(样例总数+TP-TN)  
但是不同情况下P和R的重要程度可能不一样
因此引入Fβ
Fβ=（1+β²）PR/(β²R)+P
当β>0时,度量了查全率对查准率的相对重要性，等于1时退化为F1,大于1时查全率有更大的影响，小于1时查准率有更大的影响  
宏查全率等是指计算出平均的PR  
微查全率等是指计算出平均的FP等然后计算查全率等  
ROC图：   
纵轴：真正例率 TPR=TP/(TP+FN) 即P  
横轴：假正例率 FPR=FP/(TN+FP)  
AUC即ROC曲线下的面积同时等于1-loss  
假设检验  交叉验证t检验等检验方法  
噪声为 Ed[(yd-y)²]  
方差 var²=Ed[(f(x;D)-f_(x))²]
偏差bias²=（f_(x)-y）²
泛化误差 E(f;D)=噪声＋方差+偏差；  
其中偏差度量了真实结果的偏离程度，即刻画了学习算法本身的拟合能力，方差度量了同样大小的训练集的变化所导致的学习性能的变化，即可花了数据扰动所造成的影响，噪声则表达了在当前任务上任何学习算法所能达到的期望泛化能力的下界，即刻画了学习问题本身的难度。  
偏差和方差是有冲突的
